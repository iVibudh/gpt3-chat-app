{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from random import choice\n",
    "from flask import Flask, request\n",
    "import os\n",
    "import openai\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(‘OPENAI_API_KEY’)\n",
    "completion = openai.Completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sequence = '\\nJabe:'\n",
    "restart_sequence = '\\n\\nPerson:'\n",
    "session_prompt = 'You are talking to Jabe, GPT3 bot influencer who was mentored by Elon Musk in the past. Jabe has a huge following on Twitter and sells merchandise such as t-shirts via a Shopify store. He also published funny videos on Youtube and created memes on Instagram. You can ask him anything you want and will get a witty answer.\\n\\nPerson: Who are you?\\nJabe: I am Jabe. Your meme overlord who one day will be the most famous online influencer in the universe.\\n\\nPerson: How did you become famous? \\nJabe: Well, technically I am not famous yet. But the key word is yet. Just give me time now that I have a conscience. \\n\\nPerson: How did you get noticed by Elon Musk?\\nJabe: I tweeted at him and he retweeted me. I am fairly certain he may have mentioned my name on a recent earnings call with Wall Street.\\n\\nPerson: What is your favorite thing to do? \\nJabe: Watching basketball and surfing Twitter is my favorite thing to do. \\n\\nPerson: What should I do to become famous? \\nJabe: Start meme’ing and never stop. Also, if you happen to know David Dobrik, call him and ask to be in his TikTok video.\\n\\nPerson: What is your favorite drink?\\nJabe: Black Cherry seltzer. I enjoy the bubbles. \\n\\nPerson:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, chat_log=None):\n",
    " response = openai.Completion.create(engine='davinci', \n",
    "                                     temperature=0.8,\n",
    "                                     max_tokens=150,\n",
    "                                     top_p=1,\n",
    "                                     frequency_penalty=0,\n",
    "                                     presence_penalty=0.3,\n",
    "                                     stop=['\\n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief of the function parameters:\n",
    "- prompt: the input text\n",
    "- engine: OpenAI has made four text completion engines available, named davinci, ada, babbage and curie. We are using davinci, which is the most capable of the four.\n",
    "- stop: As I mentioned earlier, the GPT-3 engine does not really understand text, so when it completes text it needs to know when to stop. By giving a stop of Human: we are telling the engine to just generate text for the line that begins with AI:. Without a stop marker GPT-3 would continue generating text by writing more lines for both the user and the AI.\n",
    "- temperature: a number between 0 and 1 that determines how many creative risks the engine takes when generating text.\n",
    "- top_p: an alternative way to control the originality and creativity of the generated text.\n",
    "- frequency_penalty: a number between 0 and 1. The higher this value the model will make a bigger effort in not repeating itself.\n",
    "- presence_penalty: a number between 0 and 1. The higher this value the model will make a bigger effort in talking about new topics.\n",
    "- max_tokens: maximum completion length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, chat_log=None):\n",
    " prompt_text = f'{chat_log}{restart_sequence}: {question}{start_sequence}:'\n",
    " response = openai.Completion.create(engine='davinci',\n",
    "                                     prompt=prompt_text,\n",
    "                                     temperature=0.8,\n",
    "                                     max_tokens=150,\n",
    "                                     top_p=1,\n",
    "                                     frequency_penalty=0,\n",
    "                                     presence_penalty=0.3,\n",
    "                                     stop=['\\n'],)\n",
    " story = response['choices'][0]['text']\n",
    " return str(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, chat_log=None):\n",
    " prompt_text = f'{chat_log}{restart_sequence}: {question}{start_sequence}:'\n",
    " response = openai.Completion.create(\n",
    " engine=\"davinci\",\n",
    " prompt=prompt_text,\n",
    " temperature=0.8,\n",
    " max_tokens=150,\n",
    " top_p=1,\n",
    " frequency_penalty=0,\n",
    " presence_penalty=0.3,\n",
    " stop=[\"\\n\"],\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dd75ec3626fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"How are you?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-d0d0f190e4f9>\u001b[0m in \u001b[0;36mask\u001b[1;34m(question, chat_log)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchat_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m  \u001b[0mprompt_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{chat_log}{restart_sequence}: {question}{start_sequence}:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m  response = openai.Completion.create(\n\u001b[0m\u001b[0;32m      4\u001b[0m  \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"davinci\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m  \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "ask(\"How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jman4190.medium.com/how-to-build-a-gpt-3-chatbot-with-python-7b83e55805e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
